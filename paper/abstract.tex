\begin{abstract}
A neural network can be viewed as a finite feature map, from which a reduced-rank Gaussian process model can be built. On the other hand, multiple correlated outputs can be represented by a neural network with shared hidden layers. In this paper, we propose a simple multi-output Gaussian process regression model based on the aforementioned two ideas. The kernel functions of multiple outputs are constructed from a multi-task neural network with shared hidden layers and task-specific layers. The correlations of the outputs are thus captured by the shared hidden layers. We compare our multi-task neural network enhanced Gaussian process (MTNN-GP) model with several existing multi-output Gaussian process models using two public datasets and one example of real-world analog integrated circuits. The results show that our model is competitive compared with these models.
\end{abstract}
